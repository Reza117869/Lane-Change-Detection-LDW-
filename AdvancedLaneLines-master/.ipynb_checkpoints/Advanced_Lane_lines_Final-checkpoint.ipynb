{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import resample\n",
    "from scipy.optimize import curve_fit\n",
    "import skimage.filters as filters\n",
    "from collections import deque\n",
    "from math import ceil\n",
    "from IPython.display import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline\n",
    "warped_size = np.array([1280, 720])\n",
    "original_size =np.array([720, 1280])\n",
    "OFFSET =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image helper functions\n",
    "* Use Table View to Display Group of Images when necessary for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_in_table (images, table_size, fig_size = (10, 10), cmap=None, titles=None, plot_title =\"None\"):\n",
    "    \"\"\"Shows images in table\n",
    "    Args:\n",
    "        images (list): list of input images\n",
    "        table_size (tuple): (cols count, rows count)\n",
    "        fig_size (tuple): picture (size x, size y) in inches\n",
    "        cmap (list): list of cmap parameters for each image\n",
    "        titles (list): list of images titles\n",
    "    \"\"\"\n",
    "    sizex = table_size [0]\n",
    "    sizey = table_size [1]\n",
    "    fig, imtable = plt.subplots (sizey, sizex, figsize = fig_size, squeeze=False)\n",
    "    for j in range (sizey):\n",
    "        for i in range (sizex):\n",
    "            im_idx = i + j*sizex\n",
    "            if (isinstance(cmap, (list, tuple))):\n",
    "                imtable [j][i].imshow (images[im_idx], cmap=cmap[i])\n",
    "            else:\n",
    "                im = images[im_idx]\n",
    "                if len(im.shape) == 3:\n",
    "                    imtable [j][i].imshow (im)\n",
    "                else:\n",
    "                    imtable [j][i].imshow (im, cmap='gray')    \n",
    "            if not titles is None:\n",
    "                imtable [j][i].set_title (titles [im_idx], fontsize=24)\n",
    "                \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=2.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration Helper Functions\n",
    "* Get Chessboard Corners from Standard Images\n",
    "* Calibrate Camera using differences in distances between expected and actual results\n",
    "* Use Calibration data to Undistort Camera Images\n",
    "<img src =\"Camera_Calibration.png\">\n",
    "* Example of how Chessboard Corners are obtained before Calibration to Undstort and use it to have a Bird's Eye Perspective\n",
    "<img src=\"Camera_calibration_Example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ChessBoard Corners \n",
    "def get_chessboard_corners(img_, x_, y_):\n",
    "    \"\"\"\n",
    "    Get Chessboard Corners for Calibration of Camera Images\n",
    "    :param img_: Image for Camera Calibration\n",
    "    :param x_: X- Axis \n",
    "    :param y_: Y- Axes\n",
    "    :return: Corners for Calibration\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_, cv2.COLOR_RGB2GRAY)\n",
    "    ret_, corners_ = cv2.findChessboardCorners(gray, (x_, y_), None)\n",
    "    return ret_, corners_\n",
    "\n",
    "\n",
    "# Calibrate Camera Function \n",
    "def camera_calibrate(images_, x_=9, y_=6, z_=3):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    \"\"\"\n",
    "    Calibrate the Camera Function\n",
    "    :return: \n",
    "    :param images_: Image series for Camera Calibration\n",
    "    :param x_: X axis points\n",
    "    :param y_: Y Axis points\n",
    "    :param z_: Z Axis points\n",
    "    :return: Matrix and Distortion array for distortion correction\n",
    "    \"\"\"\n",
    "    objp = np.zeros((x_ * y_, z_), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:x_, 0:y_].T.reshape(-1, 2)\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "    ### Read all Images in the folder One by One ####\n",
    "    for idx, fname in enumerate(images_):\n",
    "        img_ = cv2.imread(fname)\n",
    "        ret, corners = get_chessboard_corners(img_, x_, y_)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,\n",
    "                                                       (img_.shape[1], img_.shape[0]), None, None)\n",
    "    return mtx, dist\n",
    "\n",
    "# Undistort Images \n",
    "def undistort_image(mtx_, dist_, img_):\n",
    "    \"\"\"\n",
    "    Undistort the image using distortion coefficients\n",
    "    :param mtx_: Correction Matrix \n",
    "    :param dist_: Distortion Coefficient\n",
    "    :param img_: Image that needs undistortion\n",
    "    :return: Distortion Corrected Image\n",
    "    \"\"\"\n",
    "    dst = cv2.undistort(img_, mtx_, dist_, None, mtx_)\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warping & Birds Eye View Generation\n",
    "* Use Interactive Python to plot and understand what is the best set of source and destination points for each/ all the three videos of interest. After several days of experimentation we have finally arived at these numbers\n",
    "* Use Get Perspective Transform for Matrix calculation that can be used to Warp The Image to Bird's eye view and Unwarp them back to the front view\n",
    "<img src=\"Warp_Image_Final.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Source and Destination points \n",
    "def calc_warp_points():\n",
    "    \"\"\"\n",
    "    :return: Source and Destination pointts \n",
    "    \"\"\"\n",
    "    src = np.float32 ([\n",
    "        [220, 651],\n",
    "        [350, 577],\n",
    "        [828, 577],\n",
    "        [921, 651]\n",
    "    ])\n",
    "\n",
    "    dst = np.float32 ([\n",
    "            [220, 651],\n",
    "            [220, 577],\n",
    "            [921, 577],\n",
    "            [921, 651]\n",
    "        ])\n",
    "    return src, dst\n",
    "\n",
    "\n",
    "# Calculate Transform \n",
    "def calc_transform(src_, dst_):\n",
    "    \"\"\"\n",
    "    Calculate Perspective and Inverse Perspective Transform Matrices \n",
    "    :param src_: Source points\n",
    "    :param dst_: Destination Points\n",
    "    :return: Perspective Matrix and Inverse Perspective Transform Matrix\n",
    "    \"\"\"\n",
    "    M_ = cv2.getPerspectiveTransform(src_, dst_)\n",
    "    Minv_ = cv2.getPerspectiveTransform(dst_, src_)\n",
    "    return M_, Minv_\n",
    "\n",
    "\n",
    "# Get perspective transform \n",
    "def perspective_transform(M_, img_):\n",
    "    \"\"\"\n",
    "\n",
    "    :param M_: Perspective Matrix \n",
    "    :param img_ : Input Image\n",
    "    :return: Transformed Image \n",
    "    \"\"\"\n",
    "    img_size = (img_.shape[1],img_.shape[0])\n",
    "    transformed = cv2.warpPerspective(\n",
    "        img_,\n",
    "        M_, img_size,\n",
    "        flags=cv2.WARP_FILL_OUTLIERS + cv2.INTER_CUBIC)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "# Inverse Perspective Transform \n",
    "def inv_perspective_transform(Minv_, img_):\n",
    "    \"\"\"\n",
    "\n",
    "    :param M_: Inverse Perspective Transform Matrix\n",
    "    :param img_: Input Image\n",
    "    :return: Transformed Image\n",
    "    \"\"\"\n",
    "    img_size = (img_.shape[1], img_.shape[0])\n",
    "    transformed = cv2.warpPerspective(\n",
    "        img_,\n",
    "        Minv_, img_size,\n",
    "        flags=cv2.WARP_FILL_OUTLIERS + cv2.INTER_CUBIC)\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Thresholding Helper Functions\n",
    "\n",
    "<img src= \"Image_Thresholding_Final.png\">\n",
    "\n",
    "### Morphological Channel :\n",
    "* Use HLS S- Channel and Gray Channel to create Morphological Channel\n",
    "* Threshold the Morph Channel to get the most dominant features \n",
    "* Determine Levels of Thresholds using Mean and Standard Deviations \n",
    "\n",
    "### Environment Mask :\n",
    "* Use B-Channel from the LAB Colorspace to choose Yellow and Shades of Yellow \n",
    "* Use HLS Channel to filter out everything not in range of threshold.\n",
    "\n",
    "<img src= \"Detailed_ThreshProcess.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphology filter\n",
    "def morphology_filter(img_):\n",
    "    \"\"\"\n",
    "\n",
    "    :param img_: Input Image\n",
    "    :return: Morphologically Filtered Image\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_, cv2.COLOR_RGB2GRAY)\n",
    "    hls_s = cv2.cvtColor(img_, cv2.COLOR_RGB2HLS)[:, :, 2]\n",
    "    src = 0.6*hls_s + 0.4*gray\n",
    "    src = np.array(src-np.min(src)/(np.max(src)-np.min(src))).astype('float32')-0.5\n",
    "    blurf = np.zeros((1, 5))\n",
    "    blurf.fill(1)\n",
    "    src = cv2.filter2D(src, cv2.CV_32F, blurf)\n",
    "    f = np.zeros((1, 30))\n",
    "    f.fill(1)\n",
    "    l = cv2.morphologyEx(src, cv2.MORPH_OPEN, f)\n",
    "    filtered = src - l\n",
    "    return filtered\n",
    "\n",
    "\n",
    "# Image Threshold\n",
    "def img_threshold(img_):\n",
    "    \"\"\"\n",
    "\n",
    "    :param img_: Input Image\n",
    "    :return: Thresholded Image\n",
    "    \"\"\"\n",
    "    global fCount\n",
    "    global last_mask\n",
    "\n",
    "    # Use HLS, LAB Channels for Thresholding #\n",
    "    img_hls = cv2.cvtColor(img_, cv2.COLOR_RGB2HLS)\n",
    "    img_hls = cv2.medianBlur(img_hls, 5)\n",
    "    b_channel = cv2.cvtColor(img_, cv2.COLOR_RGB2LAB)[:, :, 2]\n",
    "    b_channel = cv2.medianBlur(b_channel, 5)\n",
    "\n",
    "    # Filter out Greenery & Soil from environment \n",
    "    environment = np.logical_not((b_channel > 145) & (b_channel<200) & cv2.inRange(img_hls, (0, 0, 50), (35, 192, 255))).astype(np.uint8) & (img_hls[:, :, 1] < 245)\n",
    "\n",
    "    #Deal with shadows and bright spots on the road #\n",
    "    # The shapes can be elliptical or rectangular #\n",
    "    big_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31, 31))\n",
    "    small_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    environment = cv2.morphologyEx(environment, cv2.MORPH_OPEN, small_kernel)\n",
    "    environment_mask = cv2.dilate(environment, big_kernel)\n",
    "    \n",
    "    # Use Lane from Last mask to filter ROI\n",
    "    img_mask = cv2.bitwise_and(last_mask, environment_mask)\n",
    "\n",
    "\n",
    "    # Morphology Channel Thresholding \n",
    "    morph_channel = morphology_filter(img_)\n",
    "    morph_thresh_lower = 1.2*np.mean(morph_channel) + 1.3*np.std(morph_channel)\n",
    "    morph_thresh_upper = np.max(morph_channel)\n",
    "    morph_binary = np.zeros_like(morph_channel)\n",
    "    morph_binary[(morph_channel >= morph_thresh_lower) &\n",
    "                 (morph_channel <= morph_thresh_upper)] = 1\n",
    "\n",
    "    # Erosion Kernel to clear out small granular noises\n",
    "    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    morph_binary = cv2.morphologyEx(morph_binary.astype(np.uint8), cv2.MORPH_ERODE, erosion_kernel)\n",
    "    morph_binary = cv2.morphologyEx(morph_binary, cv2.MORPH_OPEN, small_kernel)\n",
    "    combined_binary = cv2.bitwise_and(morph_binary.astype(np.uint8), img_mask.astype(np.uint8))\n",
    "\n",
    "\n",
    "    return combined_binary.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial & Mathematical Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pixels from Image \n",
    "def extract_pixels(img_):\n",
    "    \"\"\"\n",
    "    Extract all Non Zero Pixels and return X, Y Coordinates\n",
    "    :param img_: Image from which Non Zero Pixels have to be extracted\n",
    "    :return: X & Y Coordinates\n",
    "    \"\"\"\n",
    "    non_zero_pixels = np.argwhere(0 < img_)\n",
    "    x = non_zero_pixels.T[0].astype(np.float32)\n",
    "    y = non_zero_pixels.T[1].astype(np.float32)\n",
    "    return x, y\n",
    "\n",
    "# Get Intercepts \n",
    "def get_intercepts(fit, y):\n",
    "    \"\"\"\n",
    "    Get x intercepts for given y value\n",
    "    :return: \n",
    "    :param fit: The polynomial fit\n",
    "    :param y: Y Coordinates\n",
    "    :return: X Coordinates\n",
    "    \"\"\"\n",
    "    x = fit[0] * (y * y) + fit[1] * y + fit[2]\n",
    "    return x\n",
    "\n",
    "# Draw Polygon based on X, and Y points for Left and Right Lanes on Image\n",
    "def draw_polygon(left_x, right_x, left_y, right_y, img_):\n",
    "    \"\"\"\n",
    "    Get Left_x, Right_x, Left_y, Right_y, Image , return Image with Polygon\n",
    "    :return: \n",
    "    :param left_x: \n",
    "    :param right_x: \n",
    "    :param left_y: \n",
    "    :param right_y: \n",
    "    :param img_: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([left_x, left_y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_x, right_y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    img_ = cv2.polylines(img_, np.int_([pts]), isClosed=False, color=(0, 0, 255), thickness=25)\n",
    "    img_ = cv2.fillPoly(img_, np.int_(pts), (34, 255, 34))\n",
    "    return img_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking & Searching\n",
    "There are two kinds of masking adn search techniques to look for lanes \n",
    "### Blind Search \n",
    "* Scan through entire image for pixels and mask out invalid pixels\n",
    "* Left and Right masks are computed sequentially.\n",
    "* Left is computed first followed by Right which is computed after Image is masked with the left mask. \n",
    "<img src=\"BlindSearch.png\">\n",
    "\n",
    "Left Blind Search Example                 | Right Blind Search Example\n",
    "-                                         | -\n",
    "![alt](Mask_Computation_Example_Left.png) | ![alt](Mask_Computation_Example_Right.png)\n",
    "\n",
    "### Combined Mask\n",
    "* Numerically / Logically add masks to get overall mask. \n",
    "<img src=\"Left_And_Right_Mask.png\">\n",
    "\n",
    "### Polyomial Search  \n",
    "* Based on previous detected lane and interval specified . \n",
    "<img src=\"PolynomialSearch.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_to_imgpts(x, y):\n",
    "    \"\"\"\n",
    "    Convert parameters from X,Y plane to Image Plane Points\n",
    "    :param x: \n",
    "    :param y: \n",
    "    :return pts:\n",
    "    \"\"\"\n",
    "    pts = np.array([np.flipud(np.transpose(np.vstack([x, y])))])\n",
    "    return pts\n",
    "\n",
    "def draw_polylines(input_img, pts, window_size):\n",
    "    \"\"\"\n",
    "    Draw Polylines for points with given thickness specified by Window Size\n",
    "    :param input_img: \n",
    "    :param pts: \n",
    "    :param window_size: \n",
    "    :return: Image with Poly Lines \n",
    "    \"\"\"\n",
    "    return cv2.polylines(input_img, np.int_([pts]), isClosed=False, color=(255, 255, 255),\n",
    "                         thickness=2 * window_size)\n",
    "\n",
    "\n",
    "def smoothen_masks(fit, img_, window_size):\n",
    "    \"\"\"\n",
    "     # Use polyfit from the mask points for smoothening them \n",
    "    :param fit: \n",
    "    :param img_: \n",
    "    :param window_size: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    img_size = img_.shape\n",
    "    mask_poly = np.zeros_like(img_)\n",
    "    # Get top to Bottom for refactoring #\n",
    "    mask_y = np.linspace(0, img_size[0] - 1, img_size[0])\n",
    "    mask_x = get_intercepts(fit, mask_y)\n",
    "\n",
    "    # Smoothen the mask #\n",
    "    pts = coordinates_to_imgpts(mask_x, mask_y)\n",
    "    mask_poly_smooth = draw_polylines(mask_poly, pts, window_size)\n",
    "    return mask_poly_smooth\n",
    "\n",
    "# Use when Lane is Found and Polynomial fit can be used with a Tolerance window to search for lanes\n",
    "def limited_search(img_, window_size, flag='L'):\n",
    "    \"\"\"\n",
    "    Polynomial search based on previous fit\n",
    "    :param img_: \n",
    "    :param window_size: \n",
    "    :param flag: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Initialize Mask with Same Size as Image #\n",
    "    mask_poly = np.zeros_like(img_)\n",
    "    # Get previous Coefficients #\n",
    "    fit = get_last_fit(flag=flag)\n",
    "    if fit is not None:\n",
    "        mask_poly_smooth = smoothen_masks(fit, img_, window_size)\n",
    "        return mask_poly_smooth.astype(np.uint8)\n",
    "    else:\n",
    "        return mask_poly\n",
    "    \n",
    "# Sliding Window Blind Search to generate a mask for Polynomial fit generation\n",
    "def blind_search(img_, window_size = 30):\n",
    "    img_size = img_.shape\n",
    "    n_segments = 16\n",
    "    step = img_size[0]//n_segments\n",
    "    mask_L_poly = np.zeros_like(img_)\n",
    "    mask_R_poly = np.zeros_like(img_)\n",
    "    n_steps = 4\n",
    "    window_start = img_size[1]//2 - 9 * window_size\n",
    "    window_end = window_start + 6*window_size\n",
    "    sm = np.sum(img_[img_size[0]-4*step:img_size[0], window_start:window_end], axis=0)\n",
    "    sm = np.convolve(sm, np.ones((window_size,))/window_size, mode='same')\n",
    "    argmax = window_start + np.argmax(sm)\n",
    "    shift = 0\n",
    "    plt.figure(figsize=(10,6))\n",
    "    i =0\n",
    "    for last in range(img_size[0], 0, -step):\n",
    "        first_line = max(0, last - n_steps*step)\n",
    "        sm = np.sum(img_[first_line:last, :], axis=0)\n",
    "        sm = np.convolve(sm, np.ones((window_size,))/window_size, mode='same')\n",
    "        window_start = min(max(argmax + int(shift)-window_size//2, 0), img_size[1]-1)\n",
    "        window_end = min(max(argmax + int(shift) + window_size//2, 0+1), img_size[1])\n",
    "        new_argmax = window_start + np.argmax(sm[window_start:window_end])\n",
    "        new_max = np.max(sm[window_start:window_end])\n",
    "        if new_max <= 2:\n",
    "            new_argmax = argmax + int(shift)\n",
    "            shift = shift/2\n",
    "        if last != img_size[0]:\n",
    "            shift = shift*0.25 + 0.75*(new_argmax - argmax)\n",
    "        argmax = new_argmax\n",
    "        mask_L_poly = cv2.rectangle(mask_L_poly, (argmax-window_size//2, last-step), (argmax+window_size//2, last), 1, thickness=window_size)\n",
    "        \n",
    "    not_left = np.logical_not(mask_L_poly).astype(np.uint8)\n",
    "    filtered_img = cv2.bitwise_and(img_,not_left)\n",
    "    \n",
    "    window_start = img_size[1]//2 + 6 * window_size\n",
    "    window_end = window_start + 6*window_size\n",
    "    sm = np.sum(filtered_img[img_size[0]-4*step:img_size[0], window_start:window_end], axis=0)\n",
    "    sm = np.convolve(sm, np.ones((window_size,))/window_size, mode='same')\n",
    "    argmax = window_start + np.argmax(sm)\n",
    "    shift = 0\n",
    "    for last in range(img_size[0], 0, -step):\n",
    "        first_line = max(0, last - n_steps*step)\n",
    "        sm = np.sum(filtered_img[first_line:last, :], axis=0)\n",
    "        sm = np.convolve(sm, np.ones((window_size,))/window_size, mode='same')\n",
    "        window_start = min(max(argmax + int(shift)-window_size//2, 0), img_size[1]-1)\n",
    "        window_end = min(max(argmax + int(shift) + window_size//2, 0+1), img_size[1])\n",
    "        new_argmax = window_start + np.argmax(sm[window_start:window_end])\n",
    "        new_max = np.max(sm[window_start:window_end])\n",
    "        if new_max <= 2:\n",
    "            new_argmax = argmax + int(shift)\n",
    "            shift = shift/2\n",
    "        if last != img_size[0]:\n",
    "            shift = shift*0.25 + 0.75*(new_argmax - argmax)\n",
    "        argmax = new_argmax\n",
    "        mask_R_poly = cv2.rectangle(mask_R_poly, (argmax-window_size//2, last-step), (argmax+window_size//2, last), 1, thickness=window_size)\n",
    "\n",
    "    return mask_L_poly, mask_R_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Helper Functions\n",
    "<img src=\"Queues.png\">\n",
    "____________________________________\n",
    "* Queues are extremely useful tools for First In First Out queues. \n",
    "* The size of the queues when they are really large can help stabilize values very well in case of noisy conditions\n",
    "* The size of the queues can also slow down the speed at which the lanes \n",
    "\n",
    "### Fit Functions:\n",
    "____________________\n",
    "* **Mean Fit** : Get average fit over n-samples specified\n",
    "* **Predicted Fit**: Extrapolate fit values if next sample is valid\n",
    "* **Last Fit**: Last valid fit in the queue\n",
    "\n",
    "### Curvature Functions:\n",
    "___________________________\n",
    "* **Mean Curvature** : Get average curvature over n-samples specified\n",
    "* **Predicted Curvature**: Extrapolate curvature values if next sample is valid\n",
    "* **Last Curvature**: Last valid curvature in the queue\n",
    "\n",
    "### Other Functions:\n",
    "____\n",
    "* **Clear Queues**: Clear the queues completely\n",
    "* **Pop Left**: Pop the left most value in the queues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_fit(flag='L'):\n",
    "    \"\"\"\n",
    "    Get the mean value of fit \"Left\" and \"Right\" based on flag\n",
    "    :param flag: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if flag == 'L':\n",
    "        return np.mean(np.vstack(l_coeff_queue), axis =0) if len(l_coeff_queue)>1 else l_coeff_queue[-1]\n",
    "    else:\n",
    "        return np.mean(np.vstack(r_coeff_queue), axis =0) if len(r_coeff_queue)>1 else r_coeff_queue[-1]\n",
    "\n",
    "def get_predicted_fit(flag ='L'):\n",
    "    if flag =='L':\n",
    "        if len(l_coeff_queue)>1:\n",
    "            avg_diff_L = np.mean(np.vstack(np.diff(np.vstack(l_coeff_queue), axis=0)), axis =0)\n",
    "            return np.add(get_mean_fit(flag=\"L\"),avg_diff_L)\n",
    "        else:\n",
    "            return l_coeff_queue[-1]\n",
    "    else:\n",
    "        if len(r_coeff_queue)>1:\n",
    "            avg_diff_R = np.mean(np.vstack(np.diff(np.vstack(r_coeff_queue), axis =0)), axis =0)\n",
    "            return np.add(get_mean_fit(flag=\"R\"),avg_diff_R)\n",
    "        else:\n",
    "            return r_coeff_queue[-1]\n",
    "\n",
    "def get_last_fit(flag='L'):\n",
    "    \"\"\"\n",
    "    Gets the Last Fit depending on the flag \n",
    "    :param flag: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if flag == 'L':\n",
    "        return l_coeff_queue[-1]\n",
    "    else:\n",
    "        return r_coeff_queue[-1]\n",
    "\n",
    "def get_mean_curvature(flag='L'):\n",
    "    if flag =='L':\n",
    "        return np.mean(l_offset_queue), np.mean(l_curvature_queue)\n",
    "    else:\n",
    "        return np.mean(r_offset_queue), np.mean(r_curvature_queue)\n",
    "                                                \n",
    "def get_last_curvature(flag='L'):   \n",
    "    if flag =='L':\n",
    "        return l_offset_queue[-1], l_curvature_queue[-1]\n",
    "    else:\n",
    "        return r_offset_queue[-1], r_curvature_queue[-1]\n",
    "\n",
    "def return_queue_len(flag='L'):\n",
    "    if flag =='L':\n",
    "        return len(l_coeff_queue)\n",
    "    else:\n",
    "        return len(r_coeff_queue)\n",
    "\n",
    "def clear_queues():\n",
    "    l_coeff_queue.clear()\n",
    "    r_coeff_queue.clear()\n",
    "    l_offset_queue.clear()\n",
    "    l_curvature_queue.clear()\n",
    "    r_offset_queue.clear()\n",
    "    r_curvature_queue.clear()\n",
    "    detected_count =0\n",
    "    overall_offset =0\n",
    "    \n",
    "def pop_queues_left():\n",
    "    l_coeff_queue.popleft()\n",
    "    r_coeff_queue.popleft()\n",
    "    l_curvature_queue.popleft()\n",
    "    r_offset_queue.popleft()\n",
    "    r_curvature_queue.popleft()\n",
    "\n",
    "def append_linecoeffs(fit, flag='L'):\n",
    "    if flag=='L':\n",
    "        # left line Coefficients\n",
    "        l_coeff_queue.append(fit)\n",
    "    else:\n",
    "        # Right Line Coefficients\n",
    "        r_coeff_queue.append(fit)\n",
    "    return None\n",
    "\n",
    "def append_curvature(offset, curvature, flag='L'):\n",
    "    if flag =='L':\n",
    "        l_curvature_queue.append(curvature)\n",
    "        l_offset_queue.append(offset)\n",
    "    else:\n",
    "        r_curvature_queue.append(curvature)\n",
    "        r_offset_queue.append(offset)     \n",
    "    return None\n",
    "\n",
    "def append_overall_offset(left_offset, right_offset):\n",
    "    global overall_offset\n",
    "    overall_offset = 0\n",
    "    overall_offset = left_offset + right_offset\n",
    "    overall_offset = overall_offset / 2.\n",
    "    overall_offset = center_position - overall_offset\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_curvature(fit, img_):\n",
    "    img_size= img_.shape\n",
    "    y_eval = img_size[0]\n",
    "    if fit is not None:\n",
    "        a = fit[0] * xm_per_pix / ym_per_pix**2\n",
    "        b = fit[1] * xm_per_pix / ym_per_pix\n",
    "        c = fit[2] * xm_per_pix\n",
    "        y = y_eval * ym_per_pix\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    rad_curvature = pow(1 + (2*a*y + b)**2, 1.5) / math.fabs (2*a)\n",
    "    offset = calc_offset(fit,y_eval)\n",
    "    \n",
    "    return offset, rad_curvature\n",
    "\n",
    "def calc_offset(fit, y_eval):\n",
    "    \n",
    "    a = fit[0] * xm_per_pix / ym_per_pix**2\n",
    "    b = fit[1] * xm_per_pix / ym_per_pix\n",
    "    c = fit[2] * xm_per_pix\n",
    "    y = y_eval * ym_per_pix\n",
    "    return (a*y*y + b*y + c)\n",
    "\n",
    "def check_and_fit(x, y, flag='L', threshold=1000):\n",
    "    \"\"\"\n",
    "    Verify if number of pixels are satisfactory for a confident fit and then fit \n",
    "    :param x: \n",
    "    :param y: \n",
    "    :param flag: \n",
    "    :param threshold: \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    confidence_index = len(x)\n",
    "    if IsLaneFound is False:\n",
    "        threshold =500\n",
    "    if confidence_index < threshold:\n",
    "        fit = None\n",
    "        foundFlag = False\n",
    "    else:\n",
    "        fit, cov = curve_fit(lambda x, a, b, c:a*x*x+b*x + c , x, y)\n",
    "        foundFlag = True\n",
    "    return fit, foundFlag, confidence_index\n",
    "\n",
    "\n",
    "def mask_and_fit(mask, binary_warped, flag):\n",
    "    \"\"\"\n",
    "    Mask the Images and then return the equation of the lane lines\n",
    "    :return: \n",
    "    :param mask: \n",
    "    :param binary_warped: \n",
    "    :param flag: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    img = cv2.bitwise_and(binary_warped, binary_warped, mask=mask)\n",
    "    x, y = extract_pixels(img)\n",
    "    fit, foundFlag, confidence_index = check_and_fit(x, y, flag)\n",
    "    return fit, foundFlag, confidence_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvature_sanity(left_curvature, left_offset, right_curvature, right_offset):\n",
    "    \"\"\"\n",
    "    Use The current values of Curvature and Offset from Left and Right Lanes \n",
    "    to decide if Lanes are sane \n",
    "    :param left_curvature: \n",
    "    :param left_offset: \n",
    "    :param right_curvature: \n",
    "    :param right_offset: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if return_queue_len(flag='L') >= 1 and return_queue_len(flag='R') >= 1:\n",
    "        offset = center_position - (left_offset + right_offset) / 2.\n",
    "        offset_measure = np.abs(overall_offset - offset)\n",
    "        return True if offset_measure < 0.2 else False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "def update_lanewidth(left_fit, right_fit, img_):\n",
    "    \"\"\"\n",
    "    Use the left and right fit \n",
    "    :return: \n",
    "    :param left_fit: \n",
    "    :param right_fit: \n",
    "    :param img_: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    img_size = img_.shape\n",
    "    y_eval = np.linspace(0, img_size[0], 20)\n",
    "    left_x = get_intercepts(left_fit, y_eval)\n",
    "    right_x = get_intercepts(right_fit, y_eval)\n",
    "    return np.clip(right_x - left_x, 400, 800)\n",
    "\n",
    "\n",
    "def lanewidth_sanity(left_fit, right_fit, img_):\n",
    "    \"\"\"\n",
    "    \n",
    "    :return: \n",
    "    :param left_fit: \n",
    "    :param right_fit: \n",
    "    :param img_: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    global lane_width\n",
    "    img_size = img_.shape\n",
    "    ploty = np.linspace(0, img_size[0], 20)\n",
    "    left_distances = np.vstack(calc_offset(left_fit, ploty)).T\n",
    "    right_distances = np.vstack(calc_offset(right_fit, ploty)).T\n",
    "    distances = right_distances - left_distances\n",
    "    lanewidth = lane_width * xm_per_pix\n",
    "    min_lanewidth = np.mean(lanewidth) - 2.5 * np.std(lanewidth)\n",
    "    max_lanewidth = np.mean(lanewidth) + 2.5 * np.std(lanewidth)\n",
    "    passes = np.sum((min_lanewidth <= distances) & (distances <= max_lanewidth)) / len(distances[0])\n",
    "    return True if passes >= 0.95 else False\n",
    "\n",
    "\n",
    "def lanewidth_rationalize(left_fit, confidence_index_l, right_fit, confidence_index_r, img_):\n",
    "    \"\"\"\n",
    "\n",
    "    :param left_fit: \n",
    "    :param confidence_index_l: \n",
    "    :param right_fit: \n",
    "    :param confidence_index_r: \n",
    "    :param img_: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    img_size = img_.shape\n",
    "    y = np.linspace(0, img_size[0], 20)\n",
    "    if confidence_index_l > 2. * confidence_index_r or (left_fit is not None and right_fit is None):\n",
    "        x = get_intercepts(left_fit, y) + lane_width\n",
    "        right_fit, cov = curve_fit(lambda x, a, b, c: a * x * x + b * x + c, y, x)\n",
    "    elif confidence_index_r > 2. * confidence_index_l or (left_fit is None and right_fit is not None):\n",
    "        x = get_intercepts(right_fit, y) - lane_width\n",
    "        left_fit, cov = curve_fit(lambda x, a, b, c: a * x * x + b * x + c, y, x)\n",
    "\n",
    "    return left_fit, right_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Pipeline\n",
    "### Complete Process Involves\n",
    "* **Calibrate** - Use Camera Calibrate Function to get Distortion Matrix\n",
    "* **Undistort** -  Use Computed Distortion Matrix to correct for Distortion\n",
    "<img src=\"CameraCalibrationProcess.png\">\n",
    "* **Warp** - Use Warping Function to get Bird's eye view \n",
    "<img src=\"Image_Warp_Process.png\">\n",
    "* **Threshold** - Use a combination of static , dynamic thresholding with morph transformations & colorspaces to get thresholded image\n",
    "<img src=\"Threshold_Process.png\">\n",
    "\n",
    "* **Extract Pixel Information** - Use Quantity based thresholding to and extract non-zero pixels\n",
    "* **Validate and Fit** - Use Curvature and LaneWidth Sanity mechanisms to check the validity of the two fits obtained for a given frame and decide on whether to use the current fit or use an extrapolated average of the previous fits \n",
    "<img src=\"Validation_DecisionTree.png\">\n",
    "* **Project Fit on to Image ** - Convert the x, y plane points and fit to image plane points and draw polygon on the image.\n",
    "* **Unwarp** - Use Inverse Perspective Transform to unwarp the image. \n",
    "<img src=\"Unwarp_process.png\">\n",
    "\n",
    "* **Output** - Return the processed frame . \n",
    "<img src=\"Complete_process.png\">\n",
    "\n",
    "### Example Images from Each of the video \n",
    "#### Harder Challenge\n",
    "<img src=\"Harder_Challenge_Video_Pipeline.png\">\n",
    "#### Challenge Video \n",
    "<img src=\"Challenge_ Video_pipeline.png\">\n",
    "#### Project Video\n",
    "<img src=\"Project_Video_Pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Function that processes video image by image\n",
    "def process_video(img):\n",
    "    \"\"\"\n",
    "\n",
    "    :param img: \n",
    "    :return: Processed Image that is written with appropriate polygon\n",
    "    \"\"\"\n",
    "    global isPerspectiveCompute\n",
    "    global m\n",
    "    global minv\n",
    "    global IsLaneFound\n",
    "    global fCount\n",
    "    global last_mask\n",
    "    global patience\n",
    "    global lane_width\n",
    "    global disp_left \n",
    "    global disp_right\n",
    "    global lane_width\n",
    "    global xm_per_pix\n",
    "\n",
    "    # Initialize Variables\n",
    "    l_found_flag = False\n",
    "    r_found_flag = False\n",
    "    confidence_index_l = 0\n",
    "    confidence_index_r = 0\n",
    "    img_size = img.shape\n",
    "    IsLaneWidthSane = False\n",
    "    IsCuvatureSane = False\n",
    "\n",
    "    # Perform Camera Calibration and  get Distortion Coefficients #\n",
    "    undistorted_img = undistort_image(mtx, dist, img)\n",
    "\n",
    "    # Calculate Bird' Eye Transform #\n",
    "    if not isPerspectiveCompute:\n",
    "        src_, dst_ = calc_warp_points()\n",
    "        bin_ex = draw_polylines(undistorted_img, src_, 5)\n",
    "        m, minv = calc_transform(src_, dst_)\n",
    "        isPerspectiveCompute = True\n",
    "\n",
    "    # Get Bird's Eye View #\n",
    "    warped = perspective_transform(m, undistorted_img)\n",
    "    binary_warped = img_threshold(warped)\n",
    "\n",
    "    # Lane Search\n",
    "    # Polynomial Search if Lane is Found\n",
    "    if IsLaneFound:\n",
    "        \n",
    "        #Left Mask and Fit\n",
    "        mask_l_poly = limited_search(binary_warped, int(35), flag='L')\n",
    "        left_fit, l_found_flag, confidence_index_l = mask_and_fit(mask_l_poly, binary_warped, 'L')\n",
    "        \n",
    "        # Right Mask and Fit \n",
    "        mask_r_poly = limited_search(binary_warped, int(35), flag='R')\n",
    "        right_fit, r_found_flag, confidence_index_r = mask_and_fit(mask_r_poly, binary_warped, 'R')\n",
    "        \n",
    "    # Try Blind Search if Lane is Not Found\n",
    "    else:\n",
    "        mask_l_poly, mask_r_poly = blind_search(binary_warped, int(35))\n",
    "        #Mask and Fit Left and Right Lanes\n",
    "        left_fit, l_found_flag, confidence_index_l = mask_and_fit(mask_l_poly, binary_warped, 'L')\n",
    "        right_fit, r_found_flag, confidence_index_r = mask_and_fit(mask_r_poly, binary_warped, 'R')\n",
    "\n",
    "    # Check if Lane is found after searching , verify if the detected lanes are sane\n",
    "\n",
    "    if left_fit is not None or right_fit is not None:\n",
    "        # Check sanity in combination \n",
    "        if left_fit is not None and right_fit is not None:\n",
    "            IsLaneWidthSane = lanewidth_sanity(left_fit, right_fit, binary_warped)\n",
    "        if not IsLaneWidthSane:\n",
    "            left_fit, right_fit = lanewidth_rationalize(left_fit, confidence_index_l, \n",
    "                                                        right_fit, confidence_index_r, binary_warped)\n",
    " \n",
    "        # Calculate Offset and Curvature\n",
    "        left_offset, left_curvature = calc_curvature(left_fit, binary_warped)\n",
    "        right_offset,right_curvature = calc_curvature(right_fit, binary_warped)\n",
    "        IsCurvatureSane = curvature_sanity(left_curvature, left_offset, right_curvature, right_offset)\n",
    "        \n",
    "        if IsCurvatureSane is True:\n",
    "            IsLaneFound = True\n",
    "            patience = 0 \n",
    "            # Append Left & Right Lane Coefficients, Curvature, offset\n",
    "            append_linecoeffs(left_fit, flag='L')\n",
    "            append_curvature(left_offset, left_curvature, flag='L')\n",
    "            append_linecoeffs(right_fit, flag='R')\n",
    "            append_curvature(right_offset, right_curvature, flag='R')\n",
    "            append_overall_offset(left_offset, right_offset)\n",
    "            if IsLaneWidthSane is True :\n",
    "                xm_per_pix = 3.7/ np.median(lane_width)\n",
    "                lane_width = update_lanewidth(left_fit, right_fit, binary_warped)\n",
    "        else:\n",
    "            IsLaneFound = False\n",
    "            patience = patience + 1\n",
    "            if ((return_queue_len(flag='L') >1 and return_queue_len(flag='R') > 1)): \n",
    "                pop_queues_left()\n",
    "                \n",
    "                # Left & Right Fit\n",
    "                left_fit  = get_predicted_fit(flag ='L')\n",
    "                right_fit  = get_predicted_fit(flag ='R')\n",
    "\n",
    "                #Left and Right Curvature Offset\n",
    "                left_offset, left_curvature = calc_curvature(left_fit, binary_warped)\n",
    "                right_offset, right_curvature =calc_curvature(right_fit, binary_warped)\n",
    "\n",
    "                #Append Coefficients , Curvature\n",
    "                append_linecoeffs(left_fit , flag='L')\n",
    "                append_linecoeffs(right_fit, flag='R')\n",
    "                append_curvature(left_offset, left_curvature, flag='L')\n",
    "                append_curvature(right_offset, right_curvature, flag='R')\n",
    "\n",
    "                #Overall \n",
    "                append_overall_offset(left_offset, right_offset)\n",
    "\n",
    "    # If queue length is greater than 1\n",
    "    if ((return_queue_len(flag='L') >= 1 and return_queue_len(flag='R') >= 1)):         \n",
    "    \n",
    "        # Get the mean offset\n",
    "        left_fit = get_mean_fit(flag='L')\n",
    "        right_fit = get_mean_fit(flag='R')\n",
    "\n",
    "        # Left Mean offset and Right Mean offset \n",
    "        left_mean_offset, left_mean_curvature = get_mean_curvature(flag='L')\n",
    "        right_mean_offset, right_mean_curvature = get_mean_curvature(flag='R')\n",
    "\n",
    "        # Recompute masks for masking next frame\n",
    "        mask_l_poly = smoothen_masks(get_last_fit(flag='L'), binary_warped, 50)\n",
    "        mask_r_poly = smoothen_masks(get_last_fit(flag='R'), binary_warped, 50)\n",
    "        last_mask = cv2.bitwise_or(mask_l_poly, mask_r_poly)\n",
    "\n",
    "        if not IsLaneFound:\n",
    "            last_mask = np.ones_like(binary_warped)\n",
    "            \n",
    "        # Refactor, draw a polygon and unwarp the image\n",
    "        ploty = np.linspace(0, img_size[1] - 1, img_size[1])\n",
    "        leftx = get_intercepts(left_fit, ploty)\n",
    "        rightx = get_intercepts(right_fit, ploty)\n",
    "        warped_out = draw_polygon(leftx, rightx, ploty, ploty, warped)\n",
    "        unwarped_out = inv_perspective_transform(minv, warped_out)\n",
    "        output = cv2.addWeighted(img, 0.5, unwarped_out, 0.5, 0)\n",
    "        \n",
    "        if fCount%5==0:\n",
    "            disp_left = ceil(left_mean_curvature)\n",
    "            disp_right = ceil(right_mean_curvature)\n",
    "            \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        str1 = str(\"Left Mean Curvature : \") + str(disp_left)\n",
    "        str2 = str(\"Right Mean Curvature : \") + str(disp_right)\n",
    "        cv2.putText(output, str1, (120, 630), font, 1, (0, 0, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.putText(output, str2, (700, 630), font, 1, (0, 0, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        \n",
    "    # If none of it is available \n",
    "    else:\n",
    "        warped_out = img\n",
    "        unwarped_out = img\n",
    "        output = img\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        str1 = str(' Lost Lane Tracking')\n",
    "        cv2.putText(output, str1, (430, 630), font, 1, (0, 0, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        \n",
    "    fCount = fCount + 1    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables Initialize & Invoke area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'img_' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m image_series \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCarND-Advanced-Lane-Lines\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcamera_cal\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcalibration*\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m images \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(image_series)\n\u001b[1;32m---> 38\u001b[0m mtx,dist \u001b[38;5;241m=\u001b[39m \u001b[43mcamera_calibrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Video Pipeline \u001b[39;00m\n\u001b[0;32m     41\u001b[0m video1 \u001b[38;5;241m=\u001b[39m VideoFileClip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msubclip(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mcamera_calibrate\u001b[1;34m(images_, x_, y_, z_)\u001b[0m\n\u001b[0;32m     37\u001b[0m         objpoints\u001b[38;5;241m.\u001b[39mappend(objp)\n\u001b[0;32m     38\u001b[0m         imgpoints\u001b[38;5;241m.\u001b[39mappend(corners)\n\u001b[0;32m     39\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalibrateCamera(objpoints, imgpoints,\n\u001b[1;32m---> 40\u001b[0m                                                    (\u001b[43mimg_\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mtx, dist\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'img_' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#Define Length of Queue \n",
    "queue_len= 10\n",
    "fCount = 0\n",
    "\n",
    "# Coefficients Queue \n",
    "l_coeff_queue = deque(maxlen=queue_len)\n",
    "r_coeff_queue = deque(maxlen=queue_len)\n",
    "\n",
    "\n",
    "# Curvature & Offset Queue \n",
    "l_curvature_queue = deque(maxlen=queue_len)\n",
    "r_curvature_queue = deque(maxlen=queue_len)\n",
    "l_offset_queue = deque(maxlen=queue_len)\n",
    "r_offset_queue = deque(maxlen=queue_len)\n",
    "\n",
    "# Last Mask \n",
    "last_mask = np.ones(original_size).astype(np.uint8)\n",
    "pix_width = 725\n",
    "ym_per_pix = 30./original_size[0] #meters per y pixel\n",
    "lane_width = np.random.normal(pix_width,250, 20)\n",
    "xm_per_pix = 3.7/pix_width #meters per x pixel\n",
    "center_position = original_size[1] * xm_per_pix / 2.\n",
    "\n",
    "overall_offset = 0\n",
    "\n",
    "# Flags for Event based triggering of actions \n",
    "IsLaneFound=False\n",
    "isPerspectiveCompute = False\n",
    "patience = 0\n",
    "\n",
    "# Display Curvature\n",
    "disp_left = 0\n",
    "disp_right =0\n",
    "\n",
    "# Camera Calibration Routine \n",
    "image_series = '.\\\\CarND-Advanced-Lane-Lines\\\\camera_cal\\\\calibration*'\n",
    "images = glob.glob(image_series)\n",
    "mtx,dist = camera_calibrate(images)\n",
    "\n",
    "# Video Pipeline \n",
    "video1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "processed_video = video1.fl_image(process_video)\n",
    "processed_video.write_videofile(\"Debug.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
